{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "L51JCZCW7nSN",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Linear Regression \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "QdhQHDmt76a8",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "<a data-flickr-embed=\"true\" href=\"https://www.flickr.com/photos/200947226@N07/53819385178/in/dateposted-public/\" title=\"Dataset illustrating height and corresponding weight of random people \">\n",
    "  <img src=\"https://live.staticflickr.com/65535/53819385178_9db6c6fb5a_z.jpg\" width=\"400\" height=\"250\" alt=\"b\"/>\n",
    "</a>\n",
    "<script async src=\"//embedr.flickr.com/assets/client-code.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "figure 1 : Dataset of height and corresponding weight of random people \n",
    "\n",
    "\n",
    "### Problem : How can we create a Machine Learning Model   for data in figure 1 , that  predict the weight , provided the height ?\n",
    "\n",
    "On  finding the best fit line we can predict the value of weight for new value  of height.\n",
    "\n",
    "Here we try to fit a simple line to this data.\n",
    "\n",
    "The simple linear equation is:\n",
    "\n",
    " $$\\mathbf{y} = m\\mathbf{x} + c $$\n",
    "\n",
    "\n",
    "where, we need to estimate the parameters,  y -intercept($c$) and slope($m$). \n",
    "\n",
    "Simple Linear regression is a procedure to find the value of c and m which best fit the given data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "Let's see  a  simple linear regression performed on scatter plot of _height_ Vs. _weight_.\n",
    "\n",
    "\n",
    "<a data-flickr-embed=\"true\" href=\"https://www.flickr.com/photos/200947226@N07/53819384673/in/dateposted-public/\" title=\"a\"><img src=\"https://live.staticflickr.com/65535/53819384673_c792870188_z.jpg\" width=\"400\" height=\"250\" alt=\"a\"/></a><script async src=\"//embedr.flickr.com/assets/client-code.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "figure 2 : Best fit line plotted over the data of figure 1.\n",
    "\n",
    "(We will  later go in detail regarding the procedure of finding the best fit  line )\n",
    "\n",
    "\n",
    "The red line is a simple linear regression line with output $\\mathbf{y}$ as `weight` and $\\mathbf{x}$ as `height`. \n",
    "\n",
    "The  error, $\\epsilon$ is the difference between the actual value, $y_i$, and predicted value, $\\hat{y_i}$.\n",
    "\n",
    "The actual output data point, which  are  the blue dots ,  the predicted value is projection of blue dots into red regression line . \n",
    "\n",
    "Error for each output data point is shown by the vertical distance from the actual output data point to the predicted point on a regression line.\n",
    "\n",
    "The predicted output value is:\n",
    "\n",
    "$$\\hat{y_i} = mx_i+ c$$\n",
    "\n",
    "The actual output value is:\n",
    "\n",
    "$$y_i =  mx_i+ c  + \\epsilon_i$$\n",
    "\n",
    "Where $\\epsilon_i$ is a  error. \n",
    "The error $\\epsilon_i$ as ($y_{i}-\\hat{y_{i}}$) can either be positive or negative or even 0 sometimes. \n",
    "\n",
    "We can see in the figure, error  represented by vertical lines are on either side of the regression line. \n",
    "\n",
    "We square each error and sum them, called _Sum of Squared Errors_.\n",
    "\n",
    "$$\\text{Sum of Squared Errors (SSE)} = \\sum_{i=1}^{n}(y_{i}-\\hat{y_{i}})^2$$\n",
    "\n",
    "The summation is indexed from $1$ to $n$, since we have $n$ samples. \n",
    "Change in $m$ and $c$ causes change in Sum of Squared Errors. \n",
    "\n",
    "The main principle  is that we should end up choosing intercept ($m$) and slope ($$) such that the overall sum is minimum.\n",
    "\n",
    "Sum of Squared Errors (SSE) can also be written as:\n",
    "\n",
    "$$\\text{SSE} = \\sum_{i=1}^{n}(y_{i}-\\hat{y_{i}})^2 =\\sum_{i=1}^{n}(y_{i}-(c+m_1x_i))^2 $$\n",
    "\n",
    "Here, $\\hat{y_i}$ is replaced with the simple linear regression model equation,  i.e $\\hat{y_i}$ =  $m*x+c$ .\n",
    "\n",
    "\n",
    "Since $\\text{SSE}$ is a squared term, it is always positive.\n",
    "On plotting  the  value of $c$ ,$m$ in x and y axis and  evaluating corresponding SSE in z axis ,the 3D graph  would be a convex structure  facing upwards. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fig : Visualization of change in value of SSE for various combination of m and c . \n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "heights = np.linspace(150, 210, 20)\n",
    "X = heights - heights.mean()\n",
    "true_slope = 0.5\n",
    "true_intercept = 10\n",
    "noise = np.random.uniform(-5, 5, size=X.shape)\n",
    "y = true_slope * heights + true_intercept + noise\n",
    "\n",
    "# Compute best-fit slope and intercept\n",
    "m_best = np.sum((X - X.mean()) * (y - y.mean())) / np.sum((X - X.mean())**2)\n",
    "c_best = y.mean() - m_best * X.mean()\n",
    "\n",
    "# Meshgrid for slope and intercept\n",
    "m_vals = np.linspace(m_best - 5, m_best + 5, 100)\n",
    "c_vals = np.linspace(c_best - 100, c_best + 100, 100)\n",
    "M, C = np.meshgrid(m_vals, c_vals)\n",
    "\n",
    "# Compute SSE surface\n",
    "SSE = np.zeros_like(M)\n",
    "for i in range(M.shape[0]):\n",
    "    for j in range(M.shape[1]):\n",
    "        predictions = M[i, j] * X + C[i, j]\n",
    "        SSE[i, j] = np.sum((y - predictions) ** 2)\n",
    "\n",
    "# Main surface plot\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=M, y=C, z=SSE,\n",
    "    colorscale='Viridis', opacity=0.9,\n",
    "    name='SSE Surface'\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title='SSE Surface with Perpendicular Derivative Planes',\n",
    "    scene=dict(\n",
    "        xaxis_title='Slope (m)',\n",
    "        yaxis_title='Intercept (c)',\n",
    "        zaxis_title='SSE'\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The parameters at a minimum point are obtained from calculus using Gradient Decent . \n",
    "Gradient Decent is really cool concept in the AI domain till now.\n",
    "\n",
    "Before diving into Gradient Descent , we need to have clear idea regarding partial derivative. \n",
    "\n",
    "#### Partial Derivative \n",
    "Partial derivative exist for function which have 2 or more variables.\n",
    "\n",
    "For function (SSE)  $\\text{SSE} =\\sum_{i=1}^{n}(y_{i}-(c+m_1x_i))^2$, there are two variables $m$ and $c$ . \n",
    "\n",
    "There can exist the derivative of $\\text{SSE}$ with respect to $m$ and $c$ .\n",
    "\n",
    "The derivative of $\\text{SSE}$ with respect to $m$ , while $c$ remaining constant is known as partial derivative of $\\text{SSE}$ with respect to   $m$. Denoted by : $\\frac{\\partial }{\\partial m }\\sum(y_i-(m*x_i+c))^2$\n",
    "\n",
    "Similarly , the derivative of $\\text{SSE}$ with respect to $c$ , while $m$ remaining\n",
    "constant is known as partial derivative of $\\text{SSE}$ with respect to   $c$. Denoted by : $\\frac{\\partial }{\\partial c }\\sum(y_i-(m*x_i+c))^2$\n",
    "\n",
    "\n",
    "Partial derivative of SSE with respect to m is \n",
    "    \n",
    "$\\frac{\\partial }{\\partial m }\\sum(y_i-(m *x_i+c))^2$    \n",
    "= $\\sum\\frac{\\partial }{\\partial m}(y_i-(m *x_i+ c ))^2 $   \n",
    "= $ \\sum2(y_i-(m *x_i + c ))(-x_i) $    \n",
    "\n",
    "Similarly , \n",
    "Partial derivative of SSE with respect to c is \n",
    "  \n",
    "$\\frac{\\partial }{\\partial c }\\sum(y_i-(m *x_i+c))^2$  \n",
    "= $\\sum\\frac{\\partial }{\\partial c}(y_i-(m *x_i+ c ))^2 $  \n",
    "= $ \\sum2(y_i-(m *x_i + c )) $  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can visualize partial derivative in the interactive as follow :\n",
    "\n",
    "#### On selecting   $\\frac{\\partial }{\\partial c }SSE$     view ; \n",
    "-We get a yellow color vertical plane ( parallel to c- axis  and perpendicular to m-axis )  intersecting the SSE-plot .  \n",
    "-One the region of intersection we can see the white curve.   \n",
    "-The derivative of this white  curve at the specific point (red dot ) is the partial derivative of SSE with  respect to c . \n",
    "\n",
    "#### On selecting   $\\frac{\\partial }{\\partial m  }SSE$     view ; \n",
    "-We get a red color vertical plane ( parallel to m- axis  and perpendicular to c-axis )  intersecting the SSE-plot .    \n",
    "-On the region of intersection we can see the white curve.   \n",
    "-The derivative of this white curve at the specific point (red dot ) is the partial derivative of SSE with  respect to m . \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Synthetic data\n",
    "np.random.seed(42)\n",
    "heights = np.linspace(150, 210, 20)\n",
    "X = heights - heights.mean()\n",
    "true_slope = 0.5\n",
    "true_intercept = 10\n",
    "noise = np.random.uniform(-5, 5, size=X.shape)\n",
    "y = true_slope * heights + true_intercept + noise\n",
    "\n",
    "# Best-fit slope and intercept\n",
    "m_best = np.sum((X - X.mean()) * (y - y.mean())) / np.sum((X - X.mean())**2)\n",
    "c_best = y.mean() - m_best * X.mean()\n",
    "\n",
    "# Grid for main surface\n",
    "m_vals = np.linspace(m_best - 5, m_best + 5, 100)\n",
    "c_vals = np.linspace(c_best - 100, c_best + 100, 100)\n",
    "M, C = np.meshgrid(m_vals, c_vals)\n",
    "\n",
    "# SSE surface\n",
    "SSE = np.zeros_like(M)\n",
    "for i in range(M.shape[0]):\n",
    "    for j in range(M.shape[1]):\n",
    "        predictions = M[i, j] * X + C[i, j]\n",
    "        SSE[i, j] = np.sum((y - predictions) ** 2)\n",
    "\n",
    "# Points of interest\n",
    "m_point = (m_best + np.min(m_vals)) / 2\n",
    "c_point = (c_best + np.min(c_vals)) / 2\n",
    "predictions_at_point = m_point * X + c_point\n",
    "sse_point = np.sum((y - predictions_at_point) ** 2)\n",
    "\n",
    "# ∂SSE/∂m curved slice\n",
    "m_curve = np.linspace(m_best - 7, m_best + 7, 100)\n",
    "sse_m_curve = np.array([\n",
    "    np.sum((y - (m * X + c_point)) ** 2) for m in m_curve\n",
    "])\n",
    "z_m = np.tile(sse_m_curve, (2, 1))\n",
    "x_m = np.tile(m_curve, (2, 1))\n",
    "y_m = np.full_like(x_m, c_point)\n",
    "z_m[0, :] = sse_m_curve\n",
    "z_m[1, :] = np.max(SSE) * 1.05\n",
    "\n",
    "# ∂SSE/∂c curved slice\n",
    "c_curve = np.linspace(c_best - 120, c_best + 120, 100)\n",
    "sse_c_curve = np.array([\n",
    "    np.sum((y - (m_point * X + c)) ** 2) for c in c_curve\n",
    "])\n",
    "z_c = np.tile(sse_c_curve, (2, 1))\n",
    "y_c = np.tile(c_curve, (2, 1))\n",
    "x_c = np.full_like(y_c, m_point)\n",
    "z_c[0, :] = sse_c_curve\n",
    "z_c[1, :] = np.max(SSE) * 1.05\n",
    "\n",
    "# Intersection lines on SSE surface\n",
    "intersection_m = go.Scatter3d(\n",
    "    x=m_curve, y=[c_point] * len(m_curve), z=sse_m_curve,\n",
    "    mode='lines', line=dict(color='white', width=8),\n",
    "    name='∂SSE/∂m Intersection', visible=False\n",
    ")\n",
    "\n",
    "intersection_c = go.Scatter3d(\n",
    "    x=[m_point] * len(c_curve), y=c_curve, z=sse_c_curve,\n",
    "    mode='lines', line=dict(color='white', width=8),\n",
    "    name='∂SSE/∂c Intersection', visible=False\n",
    ")\n",
    "\n",
    "# Camera views\n",
    "views = {\n",
    "    \"default\": dict(eye=dict(x=-1.5, y=-1.5, z=0.8)),\n",
    "    \"dm_view\": dict(eye=dict(x=0, y=-2, z=0.8)),\n",
    "    \"dc_view\": dict(eye=dict(x=-2, y=0, z=0.8))\n",
    "}\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# SSE Surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=M, y=C, z=SSE,\n",
    "    colorscale='Viridis',\n",
    "    opacity=0.8,\n",
    "    name='SSE Surface',\n",
    "    showscale=False\n",
    "))\n",
    "\n",
    "# Base plane\n",
    "fig.add_trace(go.Surface(\n",
    "    x=M, y=C, z=np.zeros_like(M),\n",
    "    colorscale=[[0, 'lightgray'], [1, 'lightgray']],\n",
    "    opacity=0.3,\n",
    "    showscale=False,\n",
    "    name='Parameter Plane'\n",
    "))\n",
    "\n",
    "# Points on surface\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[m_point], y=[c_point], z=[0],\n",
    "    mode='markers', marker=dict(size=6, color='black'),\n",
    "    name='Parameter Point'\n",
    "))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[m_point], y=[c_point], z=[sse_point],\n",
    "    mode='markers', marker=dict(size=6, color='red'),\n",
    "    name='SSE Point'\n",
    "))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[m_point, m_point], y=[c_point, c_point], z=[0, sse_point],\n",
    "    mode='lines', line=dict(color='black', width=3, dash='dot'),\n",
    "    name='Connection'\n",
    "))\n",
    "\n",
    "# ∂SSE/∂m plane - vivid red\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_m, y=y_m, z=z_m,\n",
    "    colorscale=[[0, 'rgba(255,0,0,0.9)'], [1, 'rgba(255,0,0,0.9)']],\n",
    "    showscale=False,\n",
    "    name='∂SSE/∂m Plane',\n",
    "    visible=False,\n",
    "    surfacecolor=np.ones_like(x_m),\n",
    "    contours_z=dict(show=True, color='red', width=4)\n",
    "))\n",
    "\n",
    "# ∂SSE/∂c plane - vivid yellow\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_c, y=y_c, z=z_c,\n",
    "    colorscale=[[0, 'rgba(255,255,0,0.9)'], [1, 'rgba(255,255,0,0.9)']],  # vivid yellow\n",
    "    showscale=False,\n",
    "    name='∂SSE/∂c Plane',\n",
    "    visible=False,\n",
    "    surfacecolor=np.ones_like(y_c),\n",
    "    contours_z=dict(show=True, color='gold', width=4)\n",
    "))\n",
    "\n",
    "# Add intersection lines\n",
    "fig.add_trace(intersection_m)\n",
    "fig.add_trace(intersection_c)\n",
    "\n",
    "# Visibility masks\n",
    "default_vis = [True, True, True, True, True, False, False, False, False]\n",
    "dm_vis =     [True, True, True, True, True, True, False, True, False]\n",
    "dc_vis =     [True, True, True, True, True, False, True, False, True]\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title='SSE Surface with Derivative Planes and Intersections',\n",
    "    scene=dict(\n",
    "        xaxis_title='Slope (m)',\n",
    "        yaxis_title='Intercept (c)',\n",
    "        zaxis_title='SSE',\n",
    "        camera=views[\"default\"],\n",
    "        xaxis=dict(range=[min(m_vals)-1, max(m_vals)+1]),\n",
    "        yaxis=dict(range=[min(c_vals)-10, max(c_vals)+10]),\n",
    "        zaxis=dict(range=[0, np.max(SSE)*1.2])\n",
    "    ),\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": [\n",
    "                {\n",
    "                    \"args\": [{\"visible\": default_vis}, {\"scene.camera\": views[\"default\"]}],\n",
    "                    \"label\": \"Default View\",\n",
    "                    \"method\": \"update\"\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [{\"visible\": dm_vis}, {\"scene.camera\": views[\"dm_view\"]}],\n",
    "                    \"label\": \"∂SSE/∂m View\",\n",
    "                    \"method\": \"update\"\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [{\"visible\": dc_vis}, {\"scene.camera\": views[\"dc_view\"]}],\n",
    "                    \"label\": \"∂SSE/∂c View\",\n",
    "                    \"method\": \"update\"\n",
    "                }\n",
    "            ],\n",
    "            \"direction\": \"down\",\n",
    "            \"showactive\": True,\n",
    "            \"x\": 0.1,\n",
    "            \"xanchor\": \"left\",\n",
    "            \"y\": 1.15,\n",
    "            \"yanchor\": \"top\"\n",
    "        }\n",
    "    ],\n",
    "    annotations=[\n",
    "        dict(\n",
    "            text=\"Select view:\",\n",
    "            x=0.1, y=1.2,\n",
    "            xref=\"paper\", yref=\"paper\",\n",
    "            showarrow=False\n",
    "        )\n",
    "    ],\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Gradient Descent \n",
    "\n",
    "Lets proceed into the working mechanism of gradient descent .\n",
    "\n",
    "Initially partial derivative is calculated at random initial values of m and c as $m_0$ and $c_0$ respectively .  \n",
    "i.e At    ($m_0$ , $c_0$)   \n",
    "\n",
    "$\\frac{\\partial }{\\partial m } SSE$ =$ \\sum2(y_i-(m_0*x_i + c_0))(-x_i)$  \n",
    "\n",
    "$\\frac{\\partial }{\\partial c } SSE$ = $ \\sum2(y_i-(m_0*x_i + c_0))$  \n",
    "\n",
    "There might exist better value of m and c which lead to lower value of SSE. \n",
    "\n",
    "Hence ,  the new values of $m$ and $c$ are evaluated by :\n",
    "\n",
    "$m_1$ = $m_0$ - learning_rate * $\\frac{\\partial }{\\partial m }SSE(m_0, c_0)$ \n",
    "\n",
    "$c_1$ = $c_0$ - learning_rate * $\\frac{\\partial }{\\partial c }SSE(m_0, c_0)$ \n",
    "\n",
    "Where , learning_rate is the multiplication  factor , which decides how fast we need to change the  value of m and c , to get into optimum value.\n",
    "\n",
    "In this way we calculate $(m_2 , c_2) , (m_3 , c_3) , .......... and so on .$.  \n",
    "This operation exist untill we get no significant change at all  in value of SSE on changing the value of m and c . \n",
    "\n",
    "The  procedure mentioned above is known as gradient descent. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Synthetic data\n",
    "np.random.seed(1)\n",
    "heights = np.linspace(150, 210, 30)\n",
    "X = heights - heights.mean()\n",
    "true_m = 0.5\n",
    "true_c = 10\n",
    "noise = np.random.uniform(-5, 5, size=X.shape)\n",
    "y = true_m * X + true_c + noise\n",
    "\n",
    "# Create a grid of m and c values\n",
    "m_vals = np.linspace(true_m - 3, true_m + 3, 100)\n",
    "c_vals = np.linspace(true_c - 50, true_c + 50, 100)\n",
    "M, C = np.meshgrid(m_vals, c_vals)\n",
    "SSE = np.array([\n",
    "    np.sum((y - (m * X + c))**2)\n",
    "    for m, c in zip(M.flatten(), C.flatten())\n",
    "]).reshape(M.shape)\n",
    "\n",
    "# Animation path (parameter updates)\n",
    "n_frames = 60\n",
    "m_path = np.linspace(true_m - 2.5, true_m, n_frames)\n",
    "c_path = np.linspace(true_c - 40, true_c, n_frames)\n",
    "\n",
    "# Prepare figure\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "gs = GridSpec(1, 2, width_ratios=[1, 1])\n",
    "ax_line = fig.add_subplot(gs[0])\n",
    "ax_sse = fig.add_subplot(gs[1], projection='3d')\n",
    "\n",
    "# Line fit setup\n",
    "scatter = ax_line.scatter(X, y, color='black')\n",
    "fit_line, = ax_line.plot([], [], color='orange', lw=2)\n",
    "ax_line.set_title(\"Line Fitting\")\n",
    "ax_line.set_xlim(X.min(), X.max())\n",
    "ax_line.set_ylim(y.min() - 10, y.max() + 10)\n",
    "\n",
    "# SSE surface setup with updated color and opacity\n",
    "ax_sse.plot_surface(M, C, SSE, cmap='viridis', alpha=0.5, edgecolor='none')\n",
    "sse_dot, = ax_sse.plot([], [], [], 'ro', markersize=6)\n",
    "line_to_base, = ax_sse.plot([], [], [], 'w--', lw=1)\n",
    "ax_sse.set_title(\"SSE Surface\")\n",
    "ax_sse.set_xlabel(\"m\")\n",
    "ax_sse.set_ylabel(\"c\")\n",
    "ax_sse.set_zlabel(\"SSE\")\n",
    "ax_sse.view_init(elev=35, azim=-60)\n",
    "\n",
    "def update(frame):\n",
    "    m = m_path[frame]\n",
    "    c = c_path[frame]\n",
    "    y_pred = m * X + c\n",
    "    fit_line.set_data(X, y_pred)\n",
    "\n",
    "    # SSE value\n",
    "    sse = np.sum((y - y_pred)**2)\n",
    "    sse_dot.set_data([m], [c])\n",
    "    sse_dot.set_3d_properties([sse])\n",
    "    line_to_base.set_data([m, m], [c, c])\n",
    "    line_to_base.set_3d_properties([0, sse])\n",
    "    return fit_line, sse_dot, line_to_base\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=n_frames, interval=100, blit=True)\n",
    "\n",
    "# Display inline HTML5 animation\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDt1753kIKtn"
   },
   "source": [
    "## Implementation on Real World Dataset\n",
    "\n",
    "Here is the link to dataset :  * https://drive.google.com/file/d/1xoZ51eaK-NfLfH_0L7UB6AtNlwba_Xdx/view?usp=sharing  \n",
    "This dataset has one input, height in cm, and one output, weight in kg.  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuubnjzfJTJF"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgpitlvHI0kc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "TJAn-h7EJtCc",
    "outputId": "0ceb3a29-9008-4068-f9b6-7afdff0a77fc"
   },
   "outputs": [],
   "source": [
    "data_path = \"https://drive.google.com/uc?export=download&id=1xoZ51eaK-NfLfH_0L7UB6AtNlwba_Xdx\"\n",
    "# we can also download  the data and mention the directory within own computer as data path \n",
    "\n",
    "# Read the CSV data from the link\n",
    "data_frame = pd.read_csv(data_path)\n",
    "\n",
    "# Printfirst 5 samples from the DataFrame\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Simple Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract X and y\n",
    "\n",
    "X = data_frame.iloc[:, 0].values.reshape(-1, 1)  # Select the first column (X)\n",
    "y = data_frame.iloc[:, 1]  # Select the second column (y)\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print trained parameters\n",
    "print(\"Trained slope (m) :\", model.coef_)\n",
    "print(\"Trained intercept (C):\", model.intercept_)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Calculate Mean Squared Error  \n",
    "# Mean Squared Error = SSE / n ( n is the number of sample data )\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data and the linear regression line\n",
    "\n",
    "plt.scatter(X, y, color='blue', label='Data')\n",
    "plt.plot(X, y_pred, color='red', label='Linear Regression')\n",
    "plt.xlabel('Height in cm ')\n",
    "plt.ylabel('Weight in kg  ')\n",
    "plt.title('Linear Regression Fit: Height vs Weight ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VucR9RU9xMrY"
   },
   "source": [
    "### Predict for a query . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = model.predict([[175]])  # we can change the value to get the prediction \n",
    "print(\"Predicted weight for given height is :\", predicteder_value, 'kg ' ) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Read 1 : 1.1 OLS_Simple Linear Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
